{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting keras==2.13.1\n",
      "  Using cached keras-2.13.1-py3-none-any.whl (1.7 MB)\n",
      "Collecting tensorflow==2.13.0\n",
      "  Using cached tensorflow-2.13.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (524.1 MB)\n",
      "Requirement already satisfied: h5py>=2.9.0 in /home/ansafronov/.local/lib/python3.10/site-packages (from tensorflow==2.13.0) (3.12.1)\n",
      "Requirement already satisfied: numpy<=1.24.3,>=1.22 in /home/ansafronov/.local/lib/python3.10/site-packages (from tensorflow==2.13.0) (1.24.3)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in /home/ansafronov/.local/lib/python3.10/site-packages (from tensorflow==2.13.0) (1.14.1)\n",
      "Collecting tensorflow-estimator<2.14,>=2.13.0\n",
      "  Using cached tensorflow_estimator-2.13.0-py2.py3-none-any.whl (440 kB)\n",
      "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in /home/ansafronov/.local/lib/python3.10/site-packages (from tensorflow==2.13.0) (0.4.0)\n",
      "Collecting tensorboard<2.14,>=2.13\n",
      "  Using cached tensorboard-2.13.0-py3-none-any.whl (5.6 MB)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in /home/ansafronov/.local/lib/python3.10/site-packages (from tensorflow==2.13.0) (3.4.0)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in /home/ansafronov/.local/lib/python3.10/site-packages (from tensorflow==2.13.0) (2.1.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in /home/ansafronov/.local/lib/python3.10/site-packages (from tensorflow==2.13.0) (0.2.0)\n",
      "Requirement already satisfied: packaging in /home/ansafronov/.local/lib/python3.10/site-packages (from tensorflow==2.13.0) (23.2)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /home/ansafronov/.local/lib/python3.10/site-packages (from tensorflow==2.13.0) (2.5.0)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /home/ansafronov/.local/lib/python3.10/site-packages (from tensorflow==2.13.0) (0.37.1)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /home/ansafronov/.local/lib/python3.10/site-packages (from tensorflow==2.13.0) (1.63.0)\n",
      "Requirement already satisfied: typing-extensions<4.6.0,>=3.6.6 in /home/ansafronov/.local/lib/python3.10/site-packages (from tensorflow==2.13.0) (4.5.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in /home/ansafronov/.local/lib/python3.10/site-packages (from tensorflow==2.13.0) (18.1.1)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /home/ansafronov/.local/lib/python3.10/site-packages (from tensorflow==2.13.0) (4.25.3)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in /home/ansafronov/.local/lib/python3.10/site-packages (from tensorflow==2.13.0) (1.6.3)\n",
      "Requirement already satisfied: six>=1.12.0 in /usr/lib/python3/dist-packages (from tensorflow==2.13.0) (1.16.0)\n",
      "Requirement already satisfied: setuptools in /usr/lib/python3/dist-packages (from tensorflow==2.13.0) (59.6.0)\n",
      "Requirement already satisfied: flatbuffers>=23.1.21 in /home/ansafronov/.local/lib/python3.10/site-packages (from tensorflow==2.13.0) (24.3.25)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/lib/python3/dist-packages (from astunparse>=1.6.0->tensorflow==2.13.0) (0.37.1)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /home/ansafronov/.local/lib/python3.10/site-packages (from tensorboard<2.14,>=2.13->tensorflow==2.13.0) (3.7)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /home/ansafronov/.local/lib/python3.10/site-packages (from tensorboard<2.14,>=2.13->tensorflow==2.13.0) (2.31.0)\n",
      "Requirement already satisfied: google-auth-oauthlib<1.1,>=0.5 in /home/ansafronov/.local/lib/python3.10/site-packages (from tensorboard<2.14,>=2.13->tensorflow==2.13.0) (1.0.0)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /home/ansafronov/.local/lib/python3.10/site-packages (from tensorboard<2.14,>=2.13->tensorflow==2.13.0) (0.7.2)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in /home/ansafronov/.local/lib/python3.10/site-packages (from tensorboard<2.14,>=2.13->tensorflow==2.13.0) (2.35.0)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in /home/ansafronov/.local/lib/python3.10/site-packages (from tensorboard<2.14,>=2.13->tensorflow==2.13.0) (3.0.4)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /home/ansafronov/.local/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow==2.13.0) (4.9)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /home/ansafronov/.local/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow==2.13.0) (0.4.1)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /home/ansafronov/.local/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow==2.13.0) (5.5.0)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /home/ansafronov/.local/lib/python3.10/site-packages (from google-auth-oauthlib<1.1,>=0.5->tensorboard<2.14,>=2.13->tensorflow==2.13.0) (2.0.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/ansafronov/.local/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorboard<2.14,>=2.13->tensorflow==2.13.0) (3.3.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/ansafronov/.local/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorboard<2.14,>=2.13->tensorflow==2.13.0) (2.2.3)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/lib/python3/dist-packages (from requests<3,>=2.21.0->tensorboard<2.14,>=2.13->tensorflow==2.13.0) (3.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/ansafronov/.local/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorboard<2.14,>=2.13->tensorflow==2.13.0) (2024.2.2)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in /home/ansafronov/.local/lib/python3.10/site-packages (from werkzeug>=1.0.1->tensorboard<2.14,>=2.13->tensorflow==2.13.0) (3.0.1)\n",
      "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /home/ansafronov/.local/lib/python3.10/site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow==2.13.0) (0.6.1)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /usr/lib/python3/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<1.1,>=0.5->tensorboard<2.14,>=2.13->tensorflow==2.13.0) (3.2.0)\n",
      "Installing collected packages: tensorflow-estimator, keras, tensorboard, tensorflow\n",
      "  Attempting uninstall: tensorflow-estimator\n",
      "    Found existing installation: tensorflow-estimator 2.15.0\n",
      "    Uninstalling tensorflow-estimator-2.15.0:\n",
      "      Successfully uninstalled tensorflow-estimator-2.15.0\n",
      "  Attempting uninstall: keras\n",
      "    Found existing installation: keras 2.15.0\n",
      "    Uninstalling keras-2.15.0:\n",
      "      Successfully uninstalled keras-2.15.0\n",
      "  Attempting uninstall: tensorboard\n",
      "    Found existing installation: tensorboard 2.15.2\n",
      "    Uninstalling tensorboard-2.15.2:\n",
      "      Successfully uninstalled tensorboard-2.15.2\n",
      "  Attempting uninstall: tensorflow\n",
      "    Found existing installation: tensorflow 2.15.0\n",
      "    Uninstalling tensorflow-2.15.0:\n",
      "      Successfully uninstalled tensorflow-2.15.0\n",
      "Successfully installed keras-2.13.1 tensorboard-2.13.0 tensorflow-2.13.0 tensorflow-estimator-2.13.0\n"
     ]
    }
   ],
   "source": [
    "!pip install keras==2.13.1 tensorflow==2.13.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-25 05:56:26.679726: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-10-25 05:56:26.789816: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-10-25 05:56:26.790869: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-10-25 05:56:27.705005: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-25 05:56:34.271358: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-10-25 05:56:34.288725: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1960] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n"
     ]
    }
   ],
   "source": [
    "custom_objects = {'ChannelDropout': ChannelDropout}\n",
    "with keras.saving.custom_object_scope(custom_objects):\n",
    "    keras_model = keras.models.load_model('Pretraining/Sleep_Models/sleep_model_Fold9.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.src.engine.sequential.Sequential at 0x7be3c339ce80>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keras_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class ChannelDropout_pt(nn.Module):\n",
    "    def __init__(self, rate, noise_shape=None, seed=None):\n",
    "        super().__init__()\n",
    "        self.rate = min(1., max(0., rate))\n",
    "        self.noise_shape = noise_shape\n",
    "        self.seed = seed\n",
    "        \n",
    "    def forward(self, inputs):\n",
    "        if self.training:\n",
    "            noise_shape = self.noise_shape or [1, 1, inputs.shape[2]]\n",
    "            mask = torch.rand(noise_shape, device=inputs.device) > self.rate\n",
    "            mask = mask.expand_as(inputs).float()\n",
    "            \n",
    "            return inputs * mask / (1 - self.rate)\n",
    "        else:\n",
    "            return inputs\n",
    "    \n",
    "class ModelMDD(nn.Module):\n",
    "    def __init__(self, dropout=0.5):\n",
    "        super().__init__()\n",
    "        self.n_timesteps = 3000\n",
    "        self.n_features = 19\n",
    "\n",
    "        self.channel_dropout = ChannelDropout_pt(rate=0.25)\n",
    "        \n",
    "        # Conv1D layers\n",
    "        self.conv1 = nn.Conv1d(self.n_features, 5, kernel_size=10, stride=1, padding=0)\n",
    "        self.conv2 = nn.Conv1d(5, 10, kernel_size=10, stride=1, padding=0)\n",
    "        self.conv3 = nn.Conv1d(10, 10, kernel_size=10, stride=1, padding=0)\n",
    "        self.conv4 = nn.Conv1d(10, 15, kernel_size=5, stride=1, padding=0)\n",
    "        \n",
    "        # BatchNorm layers\n",
    "        self.bn1 = nn.BatchNorm1d(5)\n",
    "        self.bn2 = nn.BatchNorm1d(10)\n",
    "        self.bn3 = nn.BatchNorm1d(10)\n",
    "        self.bn4 = nn.BatchNorm1d(15)\n",
    "        \n",
    "        # Dense layers\n",
    "        self.fc1 = nn.Linear(15 * 184, 64)  # 184 is calculated based on the input size and conv/pool operations\n",
    "        self.fc2 = nn.Linear(64, 32)\n",
    "        self.fc3 = nn.Linear(32, 2)\n",
    "        \n",
    "        self.dropout = nn.AlphaDropout(dropout)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # Swap axes as PyTorch uses (N, C, L) format\n",
    "        x = x.permute(0, 2, 1)\n",
    "        \n",
    "        # channel dropout\n",
    "        x = self.channel_dropout(x)\n",
    "\n",
    "        # Conv layers\n",
    "        x = F.elu(self.conv1(x))\n",
    "        x = F.max_pool1d(x, 2)\n",
    "        x = self.bn1(x)\n",
    "        \n",
    "        x = F.elu(self.conv2(x))\n",
    "        x = F.max_pool1d(x, 2)\n",
    "        x = self.bn2(x)\n",
    "        \n",
    "        x = F.elu(self.conv3(x))\n",
    "        x = F.max_pool1d(x, 2)\n",
    "        x = self.bn3(x)\n",
    "        \n",
    "        x = F.elu(self.conv4(x))\n",
    "        x = F.max_pool1d(x, 2)\n",
    "        x = self.bn4(x)\n",
    "        \n",
    "        # Flatten\n",
    "        x = x.view(x.size(0), -1)\n",
    "        \n",
    "        # Dense layers\n",
    "        x = self.dropout(x)\n",
    "        x = F.elu(self.fc1(x))\n",
    "        x = self.dropout(x)\n",
    "        x = F.elu(self.fc2(x))\n",
    "        x = self.dropout(x)\n",
    "        x = F.softmax(self.fc3(x), dim=1)\n",
    "        \n",
    "        return x\n",
    "\n",
    "pytorch_model = ModelMDD()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.src.layers.core.dense.Dense at 0x7be2ba528ac0>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keras_model.layers[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to transfer weights from Keras to PyTorch\n",
    "def transfer_weights(keras_model, pytorch_model):\n",
    "    conv_layer = 1\n",
    "    batchnorm_layer = 1\n",
    "    lin_layer = 1\n",
    "    for keras_layer in keras_model.layers:\n",
    "        print(keras_layer)\n",
    "        if isinstance(keras_layer, keras.src.layers.convolutional.conv1d.Conv1D):\n",
    "            # Convert Conv1D weights\n",
    "            print('conv{}'.format(conv_layer))\n",
    "            keras_weights, keras_bias = keras_layer.get_weights()\n",
    "            pytorch_layer = getattr(pytorch_model, 'conv{}'.format(conv_layer))\n",
    "            pytorch_layer.weight.data = torch.FloatTensor(keras_weights.transpose(2, 1, 0))\n",
    "            pytorch_layer.bias.data = torch.FloatTensor(keras_bias)\n",
    "            conv_layer += 1\n",
    "        \n",
    "        elif isinstance(keras_layer, keras.src.layers.normalization.batch_normalization.BatchNormalization):\n",
    "            # Convert BatchNorm weights\n",
    "            print('bn{}'.format(batchnorm_layer))\n",
    "            keras_gamma, keras_beta, keras_running_mean, keras_running_var = keras_layer.get_weights()\n",
    "            pytorch_layer = getattr(pytorch_model, 'bn{}'.format(batchnorm_layer))\n",
    "            pytorch_layer.weight.data = torch.FloatTensor(keras_gamma)\n",
    "            pytorch_layer.bias.data = torch.FloatTensor(keras_beta)\n",
    "            pytorch_layer.running_mean.data = torch.FloatTensor(keras_running_mean)\n",
    "            pytorch_layer.running_var.data = torch.FloatTensor(keras_running_var)\n",
    "            batchnorm_layer += 1\n",
    "        \n",
    "        elif isinstance(keras_layer, keras.src.layers.core.dense.Dense):\n",
    "            # Convert Dense layer weights\n",
    "            print('fc{}'.format(lin_layer))\n",
    "            keras_weights, keras_bias = keras_layer.get_weights()\n",
    "            pytorch_layer = getattr(pytorch_model, 'fc{}'.format(lin_layer))\n",
    "            pytorch_layer.weight.data = torch.FloatTensor(keras_weights.T)\n",
    "            pytorch_layer.bias.data = torch.FloatTensor(keras_bias)\n",
    "            lin_layer += 1\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<__main__.ChannelDropout object at 0x7be2ba65c070>\n",
      "<keras.src.layers.convolutional.conv1d.Conv1D object at 0x7be2ba65c4c0>\n",
      "conv1\n",
      "<keras.src.layers.pooling.max_pooling1d.MaxPooling1D object at 0x7be2ba65c5e0>\n",
      "<keras.src.layers.normalization.batch_normalization.BatchNormalization object at 0x7be2ba65cd30>\n",
      "bn1\n",
      "<keras.src.layers.convolutional.conv1d.Conv1D object at 0x7be2ba65ceb0>\n",
      "conv2\n",
      "<keras.src.layers.pooling.max_pooling1d.MaxPooling1D object at 0x7be2ba65d2a0>\n",
      "<keras.src.layers.normalization.batch_normalization.BatchNormalization object at 0x7be2ba65da20>\n",
      "bn2\n",
      "<keras.src.layers.convolutional.conv1d.Conv1D object at 0x7be2ba65db70>\n",
      "conv3\n",
      "<keras.src.layers.pooling.max_pooling1d.MaxPooling1D object at 0x7be2ba65df90>\n",
      "<keras.src.layers.normalization.batch_normalization.BatchNormalization object at 0x7be2ba65e710>\n",
      "bn3\n",
      "<keras.src.layers.convolutional.conv1d.Conv1D object at 0x7be2ba65e860>\n",
      "conv4\n",
      "<keras.src.layers.pooling.max_pooling1d.MaxPooling1D object at 0x7be2ba65ec80>\n",
      "<keras.src.layers.normalization.batch_normalization.BatchNormalization object at 0x7be2ba65f430>\n",
      "bn4\n",
      "<keras.src.layers.reshaping.flatten.Flatten object at 0x7be2ba65f9a0>\n",
      "<keras.src.layers.regularization.alpha_dropout.AlphaDropout object at 0x7be2ba65fbe0>\n",
      "<keras.src.layers.core.dense.Dense object at 0x7be2ba65fc40>\n",
      "fc1\n",
      "<keras.src.layers.regularization.alpha_dropout.AlphaDropout object at 0x7be2ba528370>\n",
      "<keras.src.layers.core.dense.Dense object at 0x7be2ba7fe410>\n",
      "fc2\n",
      "<keras.src.layers.regularization.alpha_dropout.AlphaDropout object at 0x7be2ba528a90>\n",
      "<keras.src.layers.core.dense.Dense object at 0x7be2ba528ac0>\n",
      "fc3\n"
     ]
    }
   ],
   "source": [
    "transfer_weights(keras_model, pytorch_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ModelMDD(\n",
       "  (channel_dropout): ChannelDropout_pt()\n",
       "  (conv1): Conv1d(19, 5, kernel_size=(10,), stride=(1,))\n",
       "  (conv2): Conv1d(5, 10, kernel_size=(10,), stride=(1,))\n",
       "  (conv3): Conv1d(10, 10, kernel_size=(10,), stride=(1,))\n",
       "  (conv4): Conv1d(10, 15, kernel_size=(5,), stride=(1,))\n",
       "  (bn1): BatchNorm1d(5, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (bn2): BatchNorm1d(10, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (bn3): BatchNorm1d(10, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (bn4): BatchNorm1d(15, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (fc1): Linear(in_features=2760, out_features=64, bias=True)\n",
       "  (fc2): Linear(in_features=64, out_features=32, bias=True)\n",
       "  (fc3): Linear(in_features=32, out_features=2, bias=True)\n",
       "  (dropout): AlphaDropout(p=0.5, inplace=False)\n",
       ")"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pytorch_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Keras Conv1 weight shape: (10, 19, 5)\n",
      "PyTorch Conv1 weight shape: (5, 19, 10)\n",
      "First few values match:\n",
      "Keras: [-0.02743783  0.03102693  0.21714279 -0.03915716 -0.1352543 ]\n",
      "PyTorch: [-0.02743783  0.17163071  0.09439639  0.01808764 -0.04544811]\n"
     ]
    }
   ],
   "source": [
    "# Optional: Verify a few weights\n",
    "keras_conv1_weight = keras_model.layers[1].get_weights()[0]\n",
    "pytorch_conv1_weight = pytorch_model.conv1.weight.data.numpy()\n",
    "\n",
    "print(\"Keras Conv1 weight shape:\", keras_conv1_weight.shape)\n",
    "print(\"PyTorch Conv1 weight shape:\", pytorch_conv1_weight.shape)\n",
    "print(\"First few values match:\")\n",
    "print(\"Keras:\", keras_conv1_weight[0, 0, :5])\n",
    "print(\"PyTorch:\", pytorch_conv1_weight[0, 0, :5])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[7.5101e-15, 3.3722e-10, 3.5841e-04, 9.9964e-01, 2.7456e-16]],\n",
       "       grad_fn=<SoftmaxBackward0>)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "np.random.seed(2)\n",
    "arr = np.random.random(size=(1, 3000, 19))\n",
    "# arr = np.zeros((1, 3000, 19))\n",
    "\n",
    "torch_arr = torch.FloatTensor(arr)\n",
    "\n",
    "torch.manual_seed(0)\n",
    "pytorch_model.eval()\n",
    "pytorch_model(torch_arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       "array([[0.0000000e+00, 7.4883410e-08, 1.2655842e-09, 0.0000000e+00,\n",
       "        9.9999988e-01]], dtype=float32)>"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keras_arr = tf.convert_to_tensor(arr)\n",
    "# keras.utils.set_random_seed(0)\n",
    "keras_model(keras_arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
